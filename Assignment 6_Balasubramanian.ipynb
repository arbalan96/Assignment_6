{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 6\n",
    "\n",
    "Student : Balasubramanian A.R\n",
    "\n",
    "Batch : M.Sc Computer science, second year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "We take our dataset to be 'Cats vs Dogs' with 300 samples in each category.\n",
    "\n",
    "In this code, we first use the VGG16 net (with weights trained on ImageNet) to generate features of our training data. Once that is done, we randomly split the data into training and validation data respectively. \n",
    "We then train the modified data on a fully connected neural net with three layers. The resulting neural network is found to give almost 90-95% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(224, 224), \n",
    "        batch_size=10,\n",
    "        shuffle = False)\n",
    "\n",
    "model = applications.VGG16(include_top=False, weights='imagenet') #Importing weights from VGG16 net\n",
    "bottleneck_features_train = model.predict_generator(train_generator, 60) #Generating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([train_generator[i][1][j] for i in range(60) for j in range(10)]) #The labels of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "train_data = bottleneck_features_train #New train data\n",
    "\n",
    "#Random splitting of the data into training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data,train_labels,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360 samples, validate on 240 samples\n",
      "Epoch 1/25\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.8538 - acc: 0.6139 - val_loss: 0.3123 - val_acc: 0.9208\n",
      "Epoch 2/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.3872 - acc: 0.8111 - val_loss: 0.2601 - val_acc: 0.9125\n",
      "Epoch 3/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.2646 - acc: 0.9139 - val_loss: 0.1983 - val_acc: 0.9250\n",
      "Epoch 4/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.1993 - acc: 0.9194 - val_loss: 0.1744 - val_acc: 0.9208\n",
      "Epoch 5/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.1396 - acc: 0.9528 - val_loss: 0.1604 - val_acc: 0.9250\n",
      "Epoch 6/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.1062 - acc: 0.9611 - val_loss: 0.1513 - val_acc: 0.9417\n",
      "Epoch 7/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0814 - acc: 0.9750 - val_loss: 0.1541 - val_acc: 0.9375\n",
      "Epoch 8/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0487 - acc: 0.9833 - val_loss: 0.1435 - val_acc: 0.9500\n",
      "Epoch 9/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0470 - acc: 0.9861 - val_loss: 0.1413 - val_acc: 0.9417\n",
      "Epoch 10/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0321 - acc: 0.9944 - val_loss: 0.1535 - val_acc: 0.9417\n",
      "Epoch 11/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0331 - acc: 0.9917 - val_loss: 0.1846 - val_acc: 0.9292\n",
      "Epoch 12/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0278 - acc: 0.9917 - val_loss: 0.1696 - val_acc: 0.9458\n",
      "Epoch 13/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0239 - acc: 0.9944 - val_loss: 0.1703 - val_acc: 0.9542\n",
      "Epoch 14/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0196 - acc: 0.9972 - val_loss: 0.1706 - val_acc: 0.9458\n",
      "Epoch 15/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.1667 - val_acc: 0.9417\n",
      "Epoch 16/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.1586 - val_acc: 0.9375\n",
      "Epoch 17/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.1743 - val_acc: 0.9458\n",
      "Epoch 18/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0074 - acc: 0.9972 - val_loss: 0.1818 - val_acc: 0.9542\n",
      "Epoch 19/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9500\n",
      "Epoch 20/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 0.9972 - val_loss: 0.1903 - val_acc: 0.9458\n",
      "Epoch 21/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1976 - val_acc: 0.9458\n",
      "Epoch 22/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0069 - acc: 0.9972 - val_loss: 0.2029 - val_acc: 0.9417\n",
      "Epoch 23/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1929 - val_acc: 0.9500\n",
      "Epoch 24/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1896 - val_acc: 0.9375\n",
      "Epoch 25/25\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.9417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbce011ed68>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining a fully connected model with three layers.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = train_data.shape[1:]))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Fitting the model to our data\n",
    "model.fit(X_train,y_train,\n",
    "         epochs=25,\n",
    "         validation_data = (X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
